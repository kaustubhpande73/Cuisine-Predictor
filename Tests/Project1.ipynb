{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33fd4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748909d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.blank(\"en\")\n",
    "nlp =spacy.load(\"en_core_web_sm\")\n",
    "raw_file = open('sample.txt')\n",
    "data = raw_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a14c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Names(data):\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# doc = nlp(data)\n",
    "# for ent in doc.ents:\n",
    "#     if ent.label_ == \"PROPN\":\n",
    "#displacy.render(doc, style='ent') #visualization for entity names using displacy\n",
    "# name = []\n",
    "# ent for ent in doc.ents if ent.label == spacy.symbols.PERSON:\n",
    "    text = data\n",
    "    doc=nlp(text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    text = re.sub('\\t',' ',text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "        if ent.label_=='PERSON':\n",
    "            stats.append([entity.text,len(entity.text),'Name'])\n",
    "            text=text.replace(ent.text,'\\u2588'*len(ent.text))\n",
    "    return text\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9309d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone(data):\n",
    "    text = data\n",
    "    doc=nlp(text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    text = re.sub('\\t',' ',text)\n",
    "    regex_phone=r'\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]?\\d{4}|\\d{3}[-\\.\\s]??\\d{4}' # format - ###-###-####\n",
    "    phone=re.findall(regex_phone, text)\n",
    "    for j in phone:\n",
    "        text=text.replace(j,'\\u2588'*len(j))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3243c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email(data):\n",
    "    text = data\n",
    "    doc=nlp(text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    text = re.sub('\\t',' ',text)\n",
    "    regex_email = '[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+'\n",
    "    email = re.findall(regex_email,text)\n",
    "    for i in email:\n",
    "        text = text.replace(i,'\\u2588'*len(i))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date(data):\n",
    "    text = data\n",
    "    doc=nlp(text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    text = re.sub('\\t',' ',text)\n",
    "    \"\"\"I tried using regex, but it won't capture the right dates, so used entity label to capture dates.\n",
    "       It is not perfect but captures most dates\"\"\"\n",
    "#     regex_date = '(0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])[- /.](19|20)\\d\\d'\n",
    "#     date = re.findall(regex_date,text)\n",
    "#     for i in text:\n",
    "#         for j in date:\n",
    "#             j=j.replace(i,'\\u2588'*len(i))\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "        if ent.label_=='DATE':\n",
    "            #stats.append([entity.text,len(entity.text),'Date'])\n",
    "            text=text.replace(ent.text,'\\u2588'*len(ent.text))\n",
    "    return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb060651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender(data):\n",
    "    text = data\n",
    "    doc=nlp(text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    text = re.sub('\\t',' ',text)\n",
    "    regex_gender = r' he | He | him | Him | She | she | her | Her | Man | man | Woman | woman | Men | men | Women | women '\n",
    "    gender = re.findall(regex_gender,text)\n",
    "    for i in gender:\n",
    "        text = text.replace(i,'\\u2588'*len(i))\n",
    "    return text\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914167fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def address(data):\n",
    "    text = data\n",
    "    doc=nlp(text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    text = re.sub('\\t',' ',text)\n",
    "    regex_gender = r'^(\\d+) ?([A-Za-z](?= ))? (.*?) ([^ ]+?) ?((?<= )APT)? ?((?<= )\\d*)?$'\n",
    "    gender = re.findall(regex_gender,text)\n",
    "    for i in gender:\n",
    "        text = text.replace(i,'\\u2588'*len(i))\n",
    "    \n",
    "\n",
    "# for ent in doc.ents:\n",
    "#         #print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "#         if ent.label_=='FAC':\n",
    "#             #stats.append([entity.text,len(entity.text),'Date'])\n",
    "#             text=text.replace(ent.text,'\\u2588'*len(ent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d0a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concepts(text,concept):\n",
    "\n",
    "    sent = nltk.tokenize.line_tokenize(text)\n",
    "\n",
    "    sen_list,mean,words= [],[],[]\n",
    "\n",
    "    synaset = wordnet.synsets(concept)\n",
    "\n",
    "    for i in range(len(synaset)):\n",
    "\n",
    "        mean.append(synaset[i].lemmas()[0].name())\n",
    "\n",
    "   \n",
    "\n",
    "    for line in range(len(sent)):\n",
    "\n",
    "        words = nltk.tokenize.word_tokenize(sent[line])\n",
    "\n",
    "        flag = 0\n",
    "\n",
    "        for j in range(len(words)):\n",
    "\n",
    "            for i in range(len(mean)):\n",
    "\n",
    "                if (mean[i] == words[j] and flag == 0):\n",
    "\n",
    "                    flag = flag + 1\n",
    "\n",
    "                    sen_list.append(sent[line])\n",
    "\n",
    "    return sen_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
